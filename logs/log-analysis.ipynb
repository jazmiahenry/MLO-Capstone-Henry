{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLO - Single Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brain Name: \n",
    "## Brain Version: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use the Bonsai Custom Assessments to analyze our results. To learn more about Bonsai custom assessments, use [these documents](https://docs.microsoft.com/en-us/bonsai/guides/assess-brain)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import Video\n",
    "# import mplcursors\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Kqlmagic Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext Kqlmagic\n",
    "%config Kqlmagic.display_limit = 5 #limiting the number of rows displayed (full rows will still be stored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login to the log analytics workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_ANALYTICS_WORKSPACE_ID = \"\" \n",
    "ALIAS = 'MLO' # add your alias. Can be anything, but should not be empty\n",
    "%kql loganalytics://code;workspace=LOG_ANALYTICS_WORKSPACE_ID;alias=ALIAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import custom assessment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_name = \"\".lower() # provide brain name here\n",
    "brain_version = # provide brain version\n",
    "assessment_name = \"custom_assessment_1\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%kql\n",
    "let _brain_name = brain_name;\n",
    "let _brain_version = brain_version;\n",
    "let _assessment_name = assessment_name;\n",
    "EpisodeLog_CL\n",
    "  | where BrainName_s == _brain_name and BrainVersion_d == _brain_version and AssessmentName_s == _assessment_name\n",
    "  | join kind=inner (\n",
    "      IterationLog_CL\n",
    "      | sort by Timestamp_t desc\n",
    "  ) on EpisodeId_g\n",
    "  | project \n",
    "      AssessmentName = AssessmentName_s,\n",
    "      EpisodeId = EpisodeId_g,\n",
    "      IterationIndex = IterationIndex_d,\n",
    "      Timestamp = Timestamp_t,\n",
    "      SimConfig = parse_json(SimConfig_s),\n",
    "      SimState = parse_json(SimState_s),\n",
    "      SimAction = parse_json(SimAction_s),\n",
    "      Reward = Reward_d,\n",
    "      CumulativeReward = CumulativeReward_d,\n",
    "      GoalMetrics = parse_json(GoalMetrics_s),\n",
    "      Terminal = Terminal_b,\n",
    "      FinishReason = FinishReason_s,\n",
    "      LessonIndex = LessonIndex_d,\n",
    "      EpisodeType = EpisodeType_s\n",
    "  | order by EpisodeId asc, IterationIndex asc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert kql query results in a dataframe\n",
    "assessment_data = _kql_raw_result_.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_kql_logs(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ''' Function to format a dataframe obtained from KQL query.\n",
    "        Output format: keeps only selected columns, and flatten nested columns [SimAction, SimState, SimConfig]\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : DataFrame\n",
    "            dataframe obtained from running KQL query then exporting `_kql_raw_result_.to_dataframe()`\n",
    "    '''\n",
    "    selected_columns = [\"Timestamp\", \"IterationIndex\", \"Reward\", \"CumulativeReward\", \"Terminal\", \"SimState\", \"SimAction\", \"SimConfig\", \"EpisodeId\"]\n",
    "    nested_columns =  [ \"SimState\", \"SimAction\", \"SimConfig\"]\n",
    "    df_selected_columns = df[selected_columns]\n",
    "    series_lst = []\n",
    "    ordered_columns = [\"EpisodeId\", \"IterationIndex\", \"Reward\", \"Terminal\"]\n",
    "    for i in nested_columns:\n",
    "        new_series = df_selected_columns[i].apply(pd.Series)\n",
    "        column_names = new_series.columns.values.tolist()\n",
    "        series_lst.append(new_series)\n",
    "        if len(column_names) > 0:\n",
    "            ordered_columns.extend(column_names)\n",
    "        del(df_selected_columns[i])\n",
    "\n",
    "    series_lst.append(df_selected_columns)\n",
    "    formated_df = pd.concat(series_lst, axis=1)\n",
    "    formated_df = formated_df.sort_values(by='Timestamp',ascending=True) # reorder df based on Timestamp\n",
    "    formated_df.index = range(len(formated_df)) # re-index\n",
    "    formated_df['Timestamp']=pd.to_datetime(formated_df['Timestamp']) # convert Timestamp to datetime\n",
    "\n",
    "    formated_df = formated_df[ordered_columns]\n",
    "    \n",
    "    return formated_df.sort_values(by=[\"EpisodeId\", \"IterationIndex\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment_df_flattened = format_kql_logs(assessment_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment_df_flattened.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [\n",
    "    'IterationIndex',\n",
    "    'machines_actual_speed',\n",
    "    'machines_state',\n",
    "    'Reward',\n",
    "    'all_conveyor_levels',\n",
    "    'initial_bin_level',\n",
    "    'sink_throughput_absolute_sum'\n",
    "]\n",
    "\n",
    "df_assessment = assessment_df_flattened[selected_columns]\n",
    "\n",
    "for col in selected_columns:\n",
    "        df_assessment[col] = df_assessment[col].apply(lambda x: ast.literal_eval(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the columns\n",
    "def flatten_column(df_assessment, col_lst):\n",
    "    df_flat = pd.concat([pd.DataFrame(df_assessment[x].values.tolist()).add_prefix(x) for x in col_lst], axis=1)\n",
    "    df_assessment = pd.concat([df_flat, df_assessment.drop(col_lst, axis=1)], axis=1)\n",
    "    return df_assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the flattening function\n",
    "selected_columns = [\n",
    "    'IterationIndex',\n",
    "    'machines_actual_speed',\n",
    "    'machines_state',\n",
    "    'Reward',\n",
    "    'all_conveyor_levels',\n",
    "    'initial_bin_level',\n",
    "    'sink_throughput_absolute_sum'\n",
    "]\n",
    "df_assessment_flattened = flatten_column(df_assessment, selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 1st and 2nd iterations\n",
    "remove_iteration = [1]\n",
    "df_throughput = df_assessment_flattened\n",
    "df_throughput = df_throughput[~df_throughput['IterationIndex0'].isin(remove_iteration)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of cans generated across 100 episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_cans = df_throughput['machines_actual_speed5'].sum()\n",
    "print(f\"The total number of cans generated across 100 episodes is: {Total_cans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(8,8))\n",
    "for i in range(6):\n",
    "    column_name = 'machines_state' + str(i)\n",
    "    ax = axes[i//2,i%2]\n",
    "    ax.hist(df_assessment_flattened[column_name])\n",
    "    ax.set_title(f\"Machine {i}\")\n",
    "    ax.set_xticks([-1, 0, 1])\n",
    "fig.suptitle('Machine State')\n",
    "plt.tight_layout()\n",
    "# mplcursors.cursor(hover=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of idle, down, and running counts across 100 episodes for all machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = df_assessment_flattened.index\n",
    "total_iterations = len(index)\n",
    "down_count = 0\n",
    "run_count = 0\n",
    "idle_count = 0\n",
    "for i in range(6):\n",
    "    column_name = 'machines_state' + str(i)\n",
    "    df_down = df_assessment_flattened[df_assessment_flattened[column_name] == -1]\n",
    "    df_run = df_assessment_flattened[df_assessment_flattened[column_name] == 1]\n",
    "    df_down_sum = df_down[column_name].sum(axis = 0)\n",
    "    df_run_sum = df_run[column_name].sum(axis = 0)\n",
    "    df_idle_sum = total_iterations - df_run_sum + df_down_sum    \n",
    "    down_count += df_down_sum\n",
    "    run_count += df_run_sum\n",
    "    idle_count += df_idle_sum\n",
    "print('Total number of down occurances is', -down_count)\n",
    "print('Total number of run occurances is', run_count)\n",
    "print('Total number of idle occurances is', idle_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(8,8))\n",
    "for i in range(6):\n",
    "    column_name = 'machines_actual_speed' + str(i)\n",
    "    ax = axes[i//2,i%2]\n",
    "    ax.hist(df_assessment_flattened[column_name])\n",
    "    ax.set_title(f\"Machine {i}\")\n",
    "fig.suptitle('Machine Speed')\n",
    "plt.tight_layout()\n",
    "# mplcursors.cursor(hover=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Episode Level Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick episode with specific bin level\n",
    "# you can change which episode's results you'd like to view with this parameter\n",
    "bin_level = 18\n",
    "single_episode_df = assessment_df_flattened[assessment_df_flattened['initial_bin_level']==bin_level]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_level = single_episode_df['initial_bin_level'].iloc[0]\n",
    "print(f\"The initial bin level is: {bin_level}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machines and buffers visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line_for_iter(iter_count, df, position, node_sizes, ax, G):\n",
    "    ax.clear()\n",
    "\n",
    "    for key, val in position.items():\n",
    "        if key == \"source1\":\n",
    "            continue\n",
    "        elif key == \"sink\":\n",
    "            machine_speed = df.loc[iter_count, :][\"machines_actual_speed\"][-1]\n",
    "            plt.text(val[0]-1.2, val[1] + 0.009,\n",
    "                     'Throughput: ' + str(machine_speed), fontsize=7, color=\"green\") # throughput at the end\n",
    "        else:\n",
    "            machine_id = int(key[1:])\n",
    "            #print(machine_id)\n",
    "            machine_speed = df.loc[iter_count, :][\"machines_actual_speed\"][machine_id]\n",
    "            plt.text(val[0]-1.2, val[1] + 0.009,\n",
    "                     'Speed: ' + str(machine_speed), fontsize=7, color=\"green\") # machine speed\n",
    "            if key != \"m5\": # there isn't a conveyor between sink and m5\n",
    "                conveyor_buffer = df.loc[iter_count, :][\"conveyor_buffers\"][machine_id]\n",
    "                plt.text(val[0] + 1.2, val[1] - 0.009,\n",
    "                         'Buffer: ' + str(int(np.sum(conveyor_buffer))), fontsize=7, color=\"blue\")\n",
    "    nx.draw(G, nx.get_node_attributes(G, 'pos'),\n",
    "            with_labels=True, node_size=node_sizes, font_size=8)\n",
    "\n",
    "    ax.set_title(f\"Iteration: {iter_count}\")\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_animation(df):\n",
    "    max_iter = int(df[\"IterationIndex\"].max())\n",
    "    df_copy = df.copy()\n",
    "    df_copy.set_index(\"IterationIndex\", inplace=True)\n",
    "    # position of the nodes in the graph\n",
    "    position = {'source1': (0, 0.02), 'm0': (5, 0.02), 'm1': (10, 0.02), 'm2': (15, 0.02),\n",
    "                'm3': (20, 0.02), 'm4': (25, 0.02), 'm5': (30, 0.02), 'sink': (35, 0.02)}\n",
    "\n",
    "    # graph that will represent the manufacturing line\n",
    "    G = nx.Graph()\n",
    "    # connections between the nodes (machines)\n",
    "    G.add_edges_from([(\"source1\", \"m0\"), (\"m0\", \"m1\"), (\"m1\", \"m2\"),\n",
    "                      (\"m2\", \"m3\"), (\"m3\", \"m4\"), (\"m4\", \"m5\"), (\"m5\", \"sink\")])\n",
    "    node_sizes = [7500] * 8\n",
    "    node_sizes = [node/8 for node in node_sizes]\n",
    "    for key, val in position.items():\n",
    "        G.add_node(str(key), pos=val)\n",
    "    # Build plot\n",
    "    fig, ax = plt.subplots(figsize=(6,4), dpi=100)\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, plot_line_for_iter, frames=range(1,max_iter+1), fargs=(df_copy, position, node_sizes, ax, G))\n",
    "    ani.save('animation.mp4')\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "simple_animation(single_episode_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "Video('animation.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Throughput and cumulative reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward = single_episode_df[\"Reward\"]\n",
    "cumulative_rew = np.cumsum(reward.to_numpy())\n",
    "plt.plot(cumulative_rew)\n",
    "plt.title(\"Cumulative Sum of Reward\")\n",
    "print(f\"The cumulative reward at the end of the episode is: {cumulative_rew[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machines_speeds = np.array(single_episode_df[\"machines_actual_speed\"].to_list())\n",
    "plt.plot(machines_speeds[:, -1])\n",
    "plt.title(\"Throughput\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The total number of products at the output of the line throughout the episode is: {np.sum(machines_speeds[:, -1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of machine speeds and buffer sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "speeds = np.array(single_episode_df[\"machines_actual_speed\"].to_list())\n",
    "fig, axes = plt.subplots(3, 2, figsize=(8,8))\n",
    "for i in range(6):\n",
    "    ax = axes[i//2,i%2]\n",
    "    ax.plot(speeds[:,i])\n",
    "    ax.set_title(f\"Machine {i}\")\n",
    "fig.suptitle('Machine Speed')\n",
    "plt.tight_layout()\n",
    "# mplcursors.cursor(hover=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "machine_states = np.array(single_episode_df[\"machines_state\"].to_list())\n",
    "fig, axes = plt.subplots(3, 2, figsize=(8,8))\n",
    "for i in range(6):\n",
    "    ax = axes[i//2,i%2]\n",
    "    ax.plot(machine_states[:,i])\n",
    "    ax.set_title(f\"Machine {i}\")\n",
    "    ax.set_yticks([-1, 0, 1])\n",
    "fig.suptitle('Machine State')\n",
    "plt.tight_layout()\n",
    "# mplcursors.cursor(hover=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffers = np.array(single_episode_df[\"all_conveyor_levels\"].to_list())\n",
    "buffers_estimates = np.array(single_episode_df[\"all_conveyor_levels_estimate\"].to_list())\n",
    "fig, axes = plt.subplots(3, 2, figsize=(8,8))\n",
    "for i in range(5):\n",
    "    ax = axes[i//2,i%2]\n",
    "    ax.plot(buffers[:,i], color='r', label='Real')\n",
    "    ax.plot(buffers_estimates[:,i], color='b', label='Estimation')\n",
    "    ax.set_title(f\"Machine {i}\")\n",
    "fig.suptitle('Buffer Levels')\n",
    "plt.tight_layout()\n",
    "# mplcursors.cursor(hover=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeds = np.array(single_episode_df[\"machines_actual_speed\"].to_list())\n",
    "fig, axes = plt.subplots(3, 2, figsize=(8,8))\n",
    "for i in range(6):\n",
    "    ax = axes[i//2,i%2]\n",
    "    ax.hist(speeds[:,i])\n",
    "    ax.set_title(f\"Machine {i}\")\n",
    "fig.suptitle('Machine Speed Distribution')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine buffer\n",
    "buffers = np.array(single_episode_df[\"conveyor_buffers\"].to_list())\n",
    "fig, axes = plt.subplots(3, 2, figsize=(8,8))\n",
    "for i in range(5):\n",
    "    ax = axes[i//2,i%2]\n",
    "    ax.hist(np.sum(buffers[:,i,:],axis=1))\n",
    "    ax.set_title(f\"Buffer {i}\")\n",
    "fig.suptitle('Conveyor Buffer Distribution')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine states\n",
    "machine_states = np.array(single_episode_df[\"machines_state\"].to_list())\n",
    "fig, axes = plt.subplots(3, 2, figsize=(8,8))\n",
    "for i in range(6):\n",
    "    ax = axes[i//2,i%2]\n",
    "    ax.hist(machine_states[:,i], range=[-1.1, 1.1], align=\"mid\")\n",
    "    ax.set_title(f\"Machine {i}\")\n",
    "    ax.set_xticks([-1, 0, 1])\n",
    "fig.suptitle('Machine State Distribution')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine proxes\n",
    "prox = np.array(single_episode_df[\"conveyor_infeed_m1_prox_empty\"].to_list())\n",
    "fig, axes = plt.subplots(3, 2, figsize=(8,8))\n",
    "for i in range(5):\n",
    "    ax = axes[i//2,i%2]\n",
    "    ax.hist(prox[:,i], range=[-0, 1.1], align=\"left\")\n",
    "    ax.set_title(f\"Buffer {i}\")\n",
    "    ax.set_xticks([0, 1])\n",
    "fig.suptitle('conveyor_infeed_m1_prox_empty')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine proxes\n",
    "prox = np.array(single_episode_df[\"conveyor_infeed_m2_prox_empty\"].to_list())\n",
    "fig, axes = plt.subplots(3, 2, figsize=(8,8))\n",
    "for i in range(5):\n",
    "    ax = axes[i//2,i%2]\n",
    "    ax.hist(prox[:,i], range=[-0, 1.1], align=\"left\")\n",
    "    ax.set_title(f\"Buffer {i}\")\n",
    "    ax.set_xticks([0, 1])\n",
    "fig.suptitle('conveyor_infeed_m2_prox_empty')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine proxes\n",
    "prox = np.array(single_episode_df[\"conveyor_discharge_p1_prox_full\"].to_list())\n",
    "fig, axes = plt.subplots(3, 2, figsize=(8,8))\n",
    "for i in range(5):\n",
    "    ax = axes[i//2,i%2]\n",
    "    ax.hist(prox[:,i], range=[-0, 1.1], align=\"left\")\n",
    "    ax.set_title(f\"Buffer {i}\")\n",
    "    ax.set_xticks([0, 1])\n",
    "fig.suptitle('conveyor_discharge_p1_prox_full')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine proxes\n",
    "prox = np.array(single_episode_df[\"conveyor_discharge_p2_prox_full\"].to_list())\n",
    "fig, axes = plt.subplots(3, 2, figsize=(8,8))\n",
    "for i in range(5):\n",
    "    ax = axes[i//2,i%2]\n",
    "    ax.hist(prox[:,i], range=[-0, 1.1], align=\"left\")\n",
    "    ax.set_title(f\"Buffer {i}\")\n",
    "    ax.set_xticks([0, 1])\n",
    "fig.suptitle('conveyor_discharge_p2_prox_full')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
